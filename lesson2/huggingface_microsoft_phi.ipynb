{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a471e76f514e4c488e31c85e40fa429b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f7dd90590d7481dbe3a2a7ca624af5b",
              "IPY_MODEL_6279f7aa816e4cb3994bad4b0c3c2700",
              "IPY_MODEL_e162d56942be4042af489d300dd8dc03"
            ],
            "layout": "IPY_MODEL_9fd12b8177f24612ab56290d4869e0bd"
          }
        },
        "6f7dd90590d7481dbe3a2a7ca624af5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b4fcbfea2a049d09fa268ae5b9c5180",
            "placeholder": "​",
            "style": "IPY_MODEL_302663ccb55347caaed4a7a6cbdaae49",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6279f7aa816e4cb3994bad4b0c3c2700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed6b450ea57745d2bb99de3750b81240",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_977b54d0474c43eb8525a5c914264c12",
            "value": 2
          }
        },
        "e162d56942be4042af489d300dd8dc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96110dce364e454bbc06356710164201",
            "placeholder": "​",
            "style": "IPY_MODEL_9e405b3758f640708ec1f87dfde4df95",
            "value": " 2/2 [00:03&lt;00:00,  1.60s/it]"
          }
        },
        "9fd12b8177f24612ab56290d4869e0bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4fcbfea2a049d09fa268ae5b9c5180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "302663ccb55347caaed4a7a6cbdaae49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed6b450ea57745d2bb99de3750b81240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "977b54d0474c43eb8525a5c914264c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96110dce364e454bbc06356710164201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e405b3758f640708ec1f87dfde4df95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2KiRKJHK6uU",
        "outputId": "e6c2e633-1cb4-47c9-fcb7-6529b6b9bebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-22 15:59:08--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3832 (3.7K) [text/plain]\n",
            "Saving to: ‘minsearch.py’\n",
            "\n",
            "\rminsearch.py          0%[                    ]       0  --.-KB/s               \rminsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-22 15:59:09 (45.8 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!rm -f minsearch.py\n",
        "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"ai21>=2.13.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrtRjYKOTqcJ",
        "outputId": "03284327-1fe5-4095-86f3-5c77e339e6fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ai21>=2.13.0\n",
            "  Downloading ai21-2.14.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting ai21-tokenizer<1.0.0,>=0.12.0 (from ai21>=2.13.0)\n",
            "  Downloading ai21_tokenizer-0.12.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpx<0.28.0,>=0.27.0 (from ai21>=2.13.0)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from ai21>=2.13.0) (2.9.2)\n",
            "Collecting tenacity<9.0.0,>=8.3.0 (from ai21>=2.13.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from ai21>=2.13.0) (4.12.2)\n",
            "Collecting anyio<5.0.0,>=4.4.0 (from ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0)\n",
            "  Downloading anyio-4.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting sentencepiece<1.0.0,>=0.2.0 (from ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0)\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (0.19.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ai21>=2.13.0) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->ai21>=2.13.0)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ai21>=2.13.0) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ai21>=2.13.0) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ai21>=2.13.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=1.9.0->ai21>=2.13.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=1.9.0->ai21>=2.13.0) (2.23.4)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=4.4.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (1.2.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (2.0.7)\n",
            "Downloading ai21-2.14.1-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ai21_tokenizer-0.12.0-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading anyio-4.6.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece, tenacity, h11, anyio, httpcore, httpx, ai21-tokenizer, ai21\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.7.1\n",
            "    Uninstalling anyio-3.7.1:\n",
            "      Successfully uninstalled anyio-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ai21-2.14.1 ai21-tokenizer-0.12.0 anyio-4.6.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 sentencepiece-0.2.0 tenacity-8.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import minsearch\n",
        "\n",
        "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
        "docs_response = requests.get(docs_url)\n",
        "documents_raw = docs_response.json()\n",
        "\n",
        "documents = []\n",
        "\n",
        "for course in documents_raw:\n",
        "    course_name = course['course']\n",
        "\n",
        "    for doc in course['documents']:\n",
        "        doc['course'] = course_name\n",
        "        documents.append(doc)\n",
        "\n",
        "index = minsearch.Index(\n",
        "    text_fields=[\"question\", \"text\", \"section\"],\n",
        "    keyword_fields=[\"course\"]\n",
        ")\n",
        "\n",
        "index.fit(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL_AF97QNCej",
        "outputId": "17b96acd-7d0d-4d6d-c62e-9ef8725fd19a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<minsearch.Index at 0x79fc3c0ff280>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search(query):\n",
        "    boost = {'question': 3.0, 'section': 0.5}\n",
        "\n",
        "    results = index.search(\n",
        "        query=query,\n",
        "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
        "        boost_dict=boost,\n",
        "        num_results=5\n",
        "    )\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "N-gkfbTbNEOp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag(query):\n",
        "    search_results = search(query)\n",
        "    prompt = build_prompt(query, search_results)\n",
        "    answer = llm(prompt)\n",
        "    return answer"
      ],
      "metadata": {
        "id": "5_T7GT9jNGE_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "torch.random.manual_seed(0)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-128k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "a471e76f514e4c488e31c85e40fa429b",
            "6f7dd90590d7481dbe3a2a7ca624af5b",
            "6279f7aa816e4cb3994bad4b0c3c2700",
            "e162d56942be4042af489d300dd8dc03",
            "9fd12b8177f24612ab56290d4869e0bd",
            "7b4fcbfea2a049d09fa268ae5b9c5180",
            "302663ccb55347caaed4a7a6cbdaae49",
            "ed6b450ea57745d2bb99de3750b81240",
            "977b54d0474c43eb8525a5c914264c12",
            "96110dce364e454bbc06356710164201",
            "9e405b3758f640708ec1f87dfde4df95"
          ]
        },
        "id": "vBZOlFKHNIeG",
        "outputId": "1a63df05-16e9-4b29-a65b-732eec1b847b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a471e76f514e4c488e31c85e40fa429b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rag: retrieval\n",
        "def search(query):\n",
        "    filter_dict = {\"course\": \"data-engineering-zoomcamp\"}\n",
        "    boost_dict = {\"question\": 3, \"section\": 0.5}\n",
        "\n",
        "    results = index.search(\n",
        "        query,\n",
        "        filter_dict,\n",
        "        boost_dict\n",
        "    )\n",
        "    return results\n",
        "search_results = search(\"The course has already started can i still enroll?\")"
      ],
      "metadata": {
        "id": "flYZ1Fx4NTJH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"The course has already started can i still enroll?\"\n",
        "\n",
        "# rag: augmentation\n",
        "def build_prompt(query,search_results):\n",
        "    prompt_template=\"\"\"\n",
        "QUESTION: {question}\n",
        "\n",
        "CONTEXT: {context}\n",
        "\n",
        "ANSWER:\n",
        "\"\"\".strip()\n",
        "    context =\"\"\n",
        "    for doc in search_results:\n",
        "        context =context+f\"section: {doc['section']} \\nquestion: {doc['question']}\\n answer: {doc['text']} \\n\\n\"\n",
        "    prompt = prompt_template.format(question=query , context=context).strip()\n",
        "    return prompt\n",
        "prompt = build_prompt(query,search_results)"
      ],
      "metadata": {
        "id": "KryysGRzNeIP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "ZYpLV0UMgXSa",
        "outputId": "74721616-c668-436f-b95b-7070843e1518"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"QUESTION: The course has already started can i still enroll?\\n\\nCONTEXT: section: General course-related questions \\nquestion: Course - Can I still join the course after the start date?\\n answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute. \\n\\nsection: General course-related questions \\nquestion: Course - Can I follow the course after it finishes?\\n answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project. \\n\\nsection: General course-related questions \\nquestion: Course - When will the course start?\\n answer: The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel. \\n\\nsection: General course-related questions \\nquestion: Course - What can I do before the course starts?\\n answer: You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects. \\n\\nsection: General course-related questions \\nquestion: Course - Can I get support if I take the course in the self-paced mode?\\n answer: Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though. \\n\\nsection: General course-related questions \\nquestion: How can we contribute to the course?\\n answer: Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository. \\n\\nsection: General course-related questions \\nquestion: Course - What are the prerequisites for this course?\\n answer: GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites \\n\\nsection: General course-related questions \\nquestion: Certificate - Can I follow the course in a self-paced mode and get a certificate?\\n answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running. \\n\\nsection: General course-related questions \\nquestion: Environment - Is Python 3.9 still the recommended version to use in 2024?\\n answer: Yes, for simplicity (of troubleshooting against the recorded videos) and stability. [source]\\nBut Python 3.10 and 3.11 should work fine. \\n\\nsection: General course-related questions \\nquestion: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\\n answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date. \\n\\n\\n\\nANSWER:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "_bo3QJs-P9Gr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rag: generation\n",
        "from ai21 import AI21Client\n",
        "from ai21.models.chat import UserMessage\n",
        "import json\n",
        "# One way of passing your key to the client.\n",
        "import os\n",
        "\n",
        "# AI21_API_KEY = os.environ[\"AI21_API_KEY\"]\n",
        "AI21_API_KEY = userdata.get('AI21_API_KEY')\n",
        "client = AI21Client(api_key=AI21_API_KEY)\n",
        "\n",
        "def single_message_instruct(content):\n",
        "    messages = [UserMessage(content=content)]\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"jamba-1.5-large\",\n",
        "        messages=messages,\n",
        "        top_p=1.0 # Setting to 1 encourages different responses each call.\n",
        "    )\n",
        "    return response.to_json()\n",
        "\n"
      ],
      "metadata": {
        "id": "jLCR7deLNeez"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def llm(prompt):\n",
        "#     response = single_message_instruct(prompt)\n",
        "#     json_response = json.loads(response)\n",
        "#     content = json_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "#     return content\n",
        "def llm(prompt,generate_params=None):\n",
        "    if generate_params is None:\n",
        "        generate_params = {}\n",
        "    message = [ {\"role\": \"user\", \"content\": prompt} ]\n",
        "\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "    generation_args = {\n",
        "        \"max_new_tokens\": 500,\n",
        "        \"return_full_text\": False,\n",
        "        \"temperature\": 0.0,\n",
        "        \"do_sample\": False,\n",
        "    }\n",
        "\n",
        "    output = pipe(message, **generation_args)\n",
        "    result = output[0]['generated_text']\n",
        "    return result"
      ],
      "metadata": {
        "id": "1TNeVFNmNfcu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag(\"I just discovered the course. Can i still join it?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "ti09XJsXRh-y",
        "outputId": "9506d332-3ff1-47ed-ac00-275665d04d1f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Yes, you can still join the course after the start date. You are eligible to submit the homeworks even if you don't register. However, there will be deadlines for turning in the final projects, so make sure not to leave everything until the last minute.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SeufmDq4TJQq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}