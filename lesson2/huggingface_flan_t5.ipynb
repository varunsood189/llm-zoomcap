{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2e65f3f865d48cd9c0e8143590943b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbb61fbe2ad64ef8b8c9b5668fe99283",
              "IPY_MODEL_43bbf01df3ae40f192dbd3dbf6fee70d",
              "IPY_MODEL_c68f0d4a75674f5b843205df1cbdfb46"
            ],
            "layout": "IPY_MODEL_db51d29977c145429e3f8e6e3e8cdc1f"
          }
        },
        "bbb61fbe2ad64ef8b8c9b5668fe99283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7f7c81feb894c57b280d7ac2507c604",
            "placeholder": "​",
            "style": "IPY_MODEL_4424e9a14ae54a8cbbbb4b165b64e848",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "43bbf01df3ae40f192dbd3dbf6fee70d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7422f44f758450b8f7f64e48fe86cb1",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e07bc48c4850428dbb81bca2fc731f70",
            "value": 2
          }
        },
        "c68f0d4a75674f5b843205df1cbdfb46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08bd224b461f4e268216ca37c3169535",
            "placeholder": "​",
            "style": "IPY_MODEL_82ba50d690694c3e9b570dc971e11496",
            "value": " 2/2 [00:04&lt;00:00,  2.01s/it]"
          }
        },
        "db51d29977c145429e3f8e6e3e8cdc1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f7c81feb894c57b280d7ac2507c604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4424e9a14ae54a8cbbbb4b165b64e848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7422f44f758450b8f7f64e48fe86cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e07bc48c4850428dbb81bca2fc731f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08bd224b461f4e268216ca37c3169535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82ba50d690694c3e9b570dc971e11496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2KiRKJHK6uU",
        "outputId": "58c5f7ee-664a-4e78-f8d8-3cdeb19e3407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-22 15:18:04--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3832 (3.7K) [text/plain]\n",
            "Saving to: ‘minsearch.py’\n",
            "\n",
            "\rminsearch.py          0%[                    ]       0  --.-KB/s               \rminsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-22 15:18:04 (66.7 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!rm -f minsearch.py\n",
        "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"ai21>=2.13.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrtRjYKOTqcJ",
        "outputId": "ff35f54b-62f8-4b4b-da2a-c5156d04e02c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ai21>=2.13.0 in /usr/local/lib/python3.10/dist-packages (2.14.1)\n",
            "Requirement already satisfied: ai21-tokenizer<1.0.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from ai21>=2.13.0) (0.12.0)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from ai21>=2.13.0) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from ai21>=2.13.0) (2.9.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.3.0 in /usr/local/lib/python3.10/dist-packages (from ai21>=2.13.0) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from ai21>=2.13.0) (4.12.2)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (4.6.0)\n",
            "Requirement already satisfied: sentencepiece<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (0.2.0)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (0.19.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ai21>=2.13.0) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ai21>=2.13.0) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ai21>=2.13.0) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ai21>=2.13.0) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ai21>=2.13.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=1.9.0->ai21>=2.13.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=1.9.0->ai21>=2.13.0) (2.23.4)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=4.4.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (1.2.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1.0.0,>=0.15.0->ai21-tokenizer<1.0.0,>=0.12.0->ai21>=2.13.0) (2.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import minsearch\n",
        "\n",
        "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
        "docs_response = requests.get(docs_url)\n",
        "documents_raw = docs_response.json()\n",
        "\n",
        "documents = []\n",
        "\n",
        "for course in documents_raw:\n",
        "    course_name = course['course']\n",
        "\n",
        "    for doc in course['documents']:\n",
        "        doc['course'] = course_name\n",
        "        documents.append(doc)\n",
        "\n",
        "index = minsearch.Index(\n",
        "    text_fields=[\"question\", \"text\", \"section\"],\n",
        "    keyword_fields=[\"course\"]\n",
        ")\n",
        "\n",
        "index.fit(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL_AF97QNCej",
        "outputId": "168a2da8-f954-4348-cab6-1ceab1112977"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<minsearch.Index at 0x7fc2a503ff10>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search(query):\n",
        "    boost = {'question': 3.0, 'section': 0.5}\n",
        "\n",
        "    results = index.search(\n",
        "        query=query,\n",
        "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
        "        boost_dict=boost,\n",
        "        num_results=5\n",
        "    )\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "N-gkfbTbNEOp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag(query):\n",
        "    search_results = search(query)\n",
        "    prompt = build_prompt(query, search_results)\n",
        "    answer = llm(prompt)\n",
        "    return answer"
      ],
      "metadata": {
        "id": "5_T7GT9jNGE_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install accelerate\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\", device_map=\"auto\")\n",
        "\n",
        "input_text = \"translate English to German: How old are you?\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "outputs = model.generate(input_ids)\n",
        "print(tokenizer.decode(outputs[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "d2e65f3f865d48cd9c0e8143590943b4",
            "bbb61fbe2ad64ef8b8c9b5668fe99283",
            "43bbf01df3ae40f192dbd3dbf6fee70d",
            "c68f0d4a75674f5b843205df1cbdfb46",
            "db51d29977c145429e3f8e6e3e8cdc1f",
            "b7f7c81feb894c57b280d7ac2507c604",
            "4424e9a14ae54a8cbbbb4b165b64e848",
            "f7422f44f758450b8f7f64e48fe86cb1",
            "e07bc48c4850428dbb81bca2fc731f70",
            "08bd224b461f4e268216ca37c3169535",
            "82ba50d690694c3e9b570dc971e11496"
          ]
        },
        "id": "vBZOlFKHNIeG",
        "outputId": "f77fbe58-f504-41a5-b980-bfe4c27ca1f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2e65f3f865d48cd9c0e8143590943b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> Wie alt sind Sie?</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rag: retrieval\n",
        "def search(query):\n",
        "    filter_dict = {\"course\": \"data-engineering-zoomcamp\"}\n",
        "    boost_dict = {\"question\": 3, \"section\": 0.5}\n",
        "\n",
        "    results = index.search(\n",
        "        query,\n",
        "        filter_dict,\n",
        "        boost_dict\n",
        "    )\n",
        "    return results\n",
        "search_results = search(\"The course has already started can i still enroll?\")"
      ],
      "metadata": {
        "id": "flYZ1Fx4NTJH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"The course has already started can i still enroll?\"\n",
        "\n",
        "# rag: augmentation\n",
        "def build_prompt(query,search_results):\n",
        "    prompt_template=\"\"\"\n",
        "QUESTION: {question}\n",
        "\n",
        "CONTEXT: {context}\n",
        "\n",
        "ANSWER:\n",
        "\"\"\".strip()\n",
        "    context =\"\"\n",
        "    for doc in search_results:\n",
        "        context =context+f\"section: {doc['section']} \\nquestion: {doc['question']}\\n answer: {doc['text']} \\n\\n\"\n",
        "    prompt = prompt_template.format(question=query , context=context).strip()\n",
        "    return prompt\n",
        "prompt = build_prompt(query,search_results)"
      ],
      "metadata": {
        "id": "KryysGRzNeIP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "_bo3QJs-P9Gr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rag: generation\n",
        "from ai21 import AI21Client\n",
        "from ai21.models.chat import UserMessage\n",
        "import json\n",
        "# One way of passing your key to the client.\n",
        "import os\n",
        "\n",
        "# AI21_API_KEY = os.environ[\"AI21_API_KEY\"]\n",
        "AI21_API_KEY = userdata.get('AI21_API_KEY')\n",
        "client = AI21Client(api_key=AI21_API_KEY)\n",
        "\n",
        "def single_message_instruct(content):\n",
        "    messages = [UserMessage(content=content)]\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"jamba-1.5-large\",\n",
        "        messages=messages,\n",
        "        top_p=1.0 # Setting to 1 encourages different responses each call.\n",
        "    )\n",
        "    return response.to_json()\n",
        "\n"
      ],
      "metadata": {
        "id": "jLCR7deLNeez"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def llm(prompt):\n",
        "#     response = single_message_instruct(prompt)\n",
        "#     json_response = json.loads(response)\n",
        "#     content = json_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "#     return content\n",
        "def llm(prompt,generate_params=None):\n",
        "    if generate_params is None:\n",
        "        generate_params = {}\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        max_length=generate_params.get(\"max_length\", 100),\n",
        "        num_beams=generate_params.get(\"num_beams\", 5),\n",
        "        do_sample=generate_params.get(\"do_sample\", False),\n",
        "        temperature=generate_params.get(\"temperature\", 1.0),\n",
        "        top_k=generate_params.get(\"top_k\", 50),\n",
        "        top_p=generate_params.get(\"top_p\", 0.95),\n",
        "    )\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return result"
      ],
      "metadata": {
        "id": "1TNeVFNmNfcu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "8Km4pCGmQuf_",
        "outputId": "70011ef8-c741-44a5-d6a9-834e2bb1ff52"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"QUESTION: The course has already started can i still enroll?\\n\\nCONTEXT: section: General course-related questions \\nquestion: Course - Can I still join the course after the start date?\\n answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute. \\n\\nsection: General course-related questions \\nquestion: Course - Can I follow the course after it finishes?\\n answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project. \\n\\nsection: General course-related questions \\nquestion: Course - When will the course start?\\n answer: The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel. \\n\\nsection: General course-related questions \\nquestion: Course - What can I do before the course starts?\\n answer: You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects. \\n\\nsection: General course-related questions \\nquestion: Course - Can I get support if I take the course in the self-paced mode?\\n answer: Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though. \\n\\nsection: General course-related questions \\nquestion: How can we contribute to the course?\\n answer: Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository. \\n\\nsection: General course-related questions \\nquestion: Course - What are the prerequisites for this course?\\n answer: GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites \\n\\nsection: General course-related questions \\nquestion: Certificate - Can I follow the course in a self-paced mode and get a certificate?\\n answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running. \\n\\nsection: General course-related questions \\nquestion: Environment - Is Python 3.9 still the recommended version to use in 2024?\\n answer: Yes, for simplicity (of troubleshooting against the recorded videos) and stability. [source]\\nBut Python 3.10 and 3.11 should work fine. \\n\\nsection: General course-related questions \\nquestion: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\\n answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date. \\n\\n\\n\\nANSWER:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag(\"I just discovered the course. Can i still join it?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "ti09XJsXRh-y",
        "outputId": "6366345d-9afe-4e78-ab9b-4a742e29479b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (955 > 512). Running this sequence through the model will result in indexing errors\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SeufmDq4TJQq"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}