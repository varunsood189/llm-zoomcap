{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3362f05d-8107-474a-b4fa-75c0de2e344b",
   "metadata": {},
   "source": [
    "## Q1. Running Elastic \n",
    "\n",
    "Run Elastic Search 8.4.3, and get the cluster information. If you run it on localhost, this is how you do it:\n",
    "\n",
    "```bash\n",
    "curl localhost:9200\n",
    "```\n",
    "\n",
    "Question : What's the `version.build_hash` value?\n",
    "42f05b9372a9a4a470db3b52817899b99a76ee73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7503f16c-cd3b-456d-882e-2a8dc5363f94",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f5d178-fb1b-4772-80c1-3d7cc0943ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d9eaa-7988-484a-8dcf-96cf6552b2be",
   "metadata": {},
   "source": [
    "## Q2. Indexing the data\n",
    "\n",
    "Index the data in the same way as was shown in the course videos. Make the `course` field a keyword and the rest should be text. \n",
    "\n",
    "Don't forget to install the ElasticSearch client for Python:\n",
    "\n",
    "```bash\n",
    "pip install elasticsearch\n",
    "```\n",
    "\n",
    "Which function do you use for adding your data to elastic?\n",
    "\n",
    "* `insert`\n",
    "* `index`\n",
    "* `put`\n",
    "* `add`\n",
    " \n",
    "\n",
    "Answer : index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f95c33-89ae-40ac-a261-8a255632bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d64812-8ef5-4305-8c12-05739aa1322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d90b65a-a7c2-4bce-8a41-7f0d6b7aab42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '68482ef556f0', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'dQpPyHjhRx24sesmracvtQ', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce8ee905-2411-441d-94eb-00a86482c1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_setting = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "index_name= \"course-questions\"\n",
    "es_client.indices.create(index=index_name,body=index_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c80f0c9-ee2a-4a25-b140-26a6f42600dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e59703-971f-4720-9a9c-01ba4fd6690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [00:21<00:00, 43.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name,document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64e5c1b-67aa-4617-a720-618d089a6200",
   "metadata": {},
   "source": [
    "\n",
    "## Q3. Searching\n",
    "\n",
    "Now let's search in our index. \n",
    "\n",
    "We will execute a query \"How do I execute a command in a running docker container?\". \n",
    "\n",
    "Use only `question` and `text` fields and give `question` a boost of 4, and use `\"type\": \"best_fields\"`.\n",
    "\n",
    "What's the score for the top ranking result?\n",
    "\n",
    "* 94.05\n",
    "* 84.05\n",
    "* 74.05\n",
    "* 64.05\n",
    "\n",
    "Look at the `_score` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac0fe92-3952-45bf-a25e-108b73848ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"How do I execute a command in a running docker container?\" \n",
    "search_query= {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b999959-9a99-4c4e-b7a2-22deef56f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= es_client.search(index=index_name,body=search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7239ecd-a87b-4eae-9185-7c9bf9a230d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.480255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"hits\"][\"hits\"][0][\"_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdcfcab-d028-47b4-8099-28459129d3f8",
   "metadata": {},
   "source": [
    "## Q4. Filtering\n",
    "\n",
    "Now let's only limit the questions to `machine-learning-zoomcamp`.\n",
    "\n",
    "Return 3 results. What's the 3rd question returned by the search engine?\n",
    "\n",
    "* How do I debug a docker container?\n",
    "* How do I copy files from a different folder into docker container’s working directory?\n",
    "* How do Lambda container images work?\n",
    "* How can I annotate a graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "716e36f9-57fd-4285-8681-61e433659afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I execute a command in a running docker container?\"\n",
    "\n",
    "search_query= {\n",
    "    \"size\": 3,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"machine-learning-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e5c0578-1bf2-45cc-96df-f046533aa6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response= es_client.search(index=index_name,body=search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcc7ba72-5c5e-4588-8c4d-458338f568ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'course-questions',\n",
       " '_id': 'zdXjGZIBRipWqwGTLoOJ',\n",
       " '_score': 49.61703,\n",
       " '_source': {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I copy files from a different folder into docker container’s working directory?',\n",
       "  'course': 'machine-learning-zoomcamp'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"hits\"][\"hits\"][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0582530a-c1bc-4db5-95cc-5651e5c77071",
   "metadata": {},
   "source": [
    "## Q5. Building a prompt\n",
    "\n",
    "Now we're ready to build a prompt to send to an LLM. \n",
    "\n",
    "Take the records returned from Elasticsearch in Q4 and use this template to build the context. Separate context entries by two linebreaks (`\\n\\n`)\n",
    "```python\n",
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "```\n",
    "\n",
    "Now use the context you just created along with the \"How do I execute a command in a running docker container?\" question \n",
    "to construct a prompt using the template below:\n",
    "\n",
    "```\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "```\n",
    "\n",
    "What's the length of the resulting prompt? (use the `len` function)\n",
    "\n",
    "* 962\n",
    "* 1462\n",
    "* 1962\n",
    "* 2462\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11303c19-f630-47ca-801a-cc6285f82fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag: augmentation \n",
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "search_results = es_client.search(index=index_name,body=search_query)\n",
    "context_=[]\n",
    "for hit in response[\"hits\"][\"hits\"]:        \n",
    "    context = context_template.format(question= hit[\"_source\"][\"question\"], text=hit[\"_source\"][\"text\"])\n",
    "    context_.append(context)\n",
    "context = '\\n\\n'.join(context_)\n",
    "prompt = prompt_template.format(question=query , context=context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b5d414-4382-45dc-a3fd-9a582bea2586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\\nUse only the facts from the CONTEXT when answering the QUESTION.\\n\\nQUESTION: How do I execute a command in a running docker container?\\n\\nCONTEXT:\\nQ: How do I debug a docker container?\\nA: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)\\n\\nQ: How do I copy files from my local machine to docker container?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\\n\\nQ: How do I copy files from a different folder into docker container’s working directory?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f610266-882e-48b6-964d-0778b304b168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1462"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f0ce62-9ed7-4a43-a63d-b90cff21e889",
   "metadata": {},
   "source": [
    "\n",
    "## Q6. Tokens\n",
    "\n",
    "When we use the OpenAI Platform, we're charged by the number of \n",
    "tokens we send in our prompt and receive in the response.\n",
    "\n",
    "The OpenAI python package uses `tiktoken` for tokenization:\n",
    "\n",
    "```bash\n",
    "pip install tiktoken\n",
    "```\n",
    "\n",
    "Let's calculate the number of tokens in our query: \n",
    "\n",
    "```python\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "```\n",
    "\n",
    "Use the `encode` function. How many tokens does our prompt have?\n",
    "\n",
    "* 122\n",
    "* 222\n",
    "* 322\n",
    "* 422\n",
    "\n",
    "Note: to decode back a token into a word, you can use the `decode_single_token_bytes` function:\n",
    "\n",
    "```python\n",
    "encoding.decode_single_token_bytes(63842)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "873500cb-5481-464c-9e8f-b001f3c6c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tiktoken\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bcf720c-0bfa-4845-abdc-2df8daaa7a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e616ae3-9531-40aa-a2b6-96e6ff3aacf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd46a412-1b90-474b-a1ce-d5dde01bdf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dbd859c-649b-4729-b9e7-7659b74c50a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"You're\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode_single_token_bytes(63842)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52d5dca-de61-4b88-9387-052c8e9f02c1",
   "metadata": {},
   "source": [
    "## Bonus: generating the answer (ungraded)\n",
    "\n",
    "Let's send the prompt to OpenAI. What's the response?  \n",
    "\n",
    "#### sending to jamba-1.5-large donot have access to openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27ee27e6-d3fe-4cca-bd2c-6675570e653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8ad96cb-5d5d-48ba-b7fa-2b207c99699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63744/2081732717.py:17: DeprecationWarning: The 'to_json' method is deprecated and will be removed in a future version. Please use Pydantic's built-in methods instead.\n",
      "  return response.to_json()\n"
     ]
    }
   ],
   "source": [
    "# rag: generation \n",
    "from ai21 import AI21Client\n",
    "from ai21.models.chat import UserMessage\n",
    "\n",
    "# One way of passing your key to the client.\n",
    "import os\n",
    "AI21_API_KEY = os.environ[\"AI21_API_KEY\"]\n",
    "client = AI21Client(api_key=AI21_API_KEY)\n",
    "\n",
    "def single_message_instruct(content):\n",
    "    messages = [UserMessage(content=content)]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"jamba-1.5-large\",\n",
    "        messages=messages,\n",
    "        top_p=1.0 # Setting to 1 encourages different responses each call.\n",
    "    )\n",
    "    return response.to_json()\n",
    "\n",
    "def llm(prompt):\n",
    "    response = single_message_instruct(prompt)\n",
    "    json_response = json.loads(response)\n",
    "    content = json_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return content\n",
    "answer = llm(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d82a97b-a432-479d-979b-fc11dc1f2a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  How do I execute a command in a running docker container?\n",
      "answer:  To execute a command in a running Docker container, follow these steps:\n",
      "\n",
      "1. Use the `docker ps` command to find the container ID of the running container.\n",
      "2. Use the `docker exec -it <container-id> bash` command to execute a command in the specific container.\n"
     ]
    }
   ],
   "source": [
    "print(\"query: \",query)\n",
    "print(\"answer: \",answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e0e92-4f72-4d13-b67b-ae528f2c433d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
